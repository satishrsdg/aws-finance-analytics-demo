{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of S3 objects using Python\n",
    "\n",
    "**Data Set**\n",
    "[Kagggle Financial Data Set](https://www.kaggle.com/borismarjanovic/price-volume-data-for-all-us-stocks-etfs/downloads/price-volume-data-for-all-us-stocks-etfs.zip/3)\n",
    "_Note:_ Only \"\"aapl\" and \"ge\" uploaded\n",
    "\n",
    "This demo shows the following:\n",
    "* List objects in an S3 bucket\n",
    "* Use python Boto3 package to programmatically connect to S3 and process objects\n",
    "* Use pandas to calculate the size of the folders\n",
    "* Load the files into dataframe\n",
    "\n",
    "------------\n",
    "## List the folders in s3 bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```console\n",
    "!aws s3 ls --profile fin-demo\n",
    "2019-09-13 11:16:34 rsdg-fin-demo-price-eu-west-2\n",
    "2019-09-13 11:16:34 rsdg-fin-demo-reference-eu-west-2\n",
    "2019-09-13 11:16:34 rsdg-fin-demo-transaction-eu-west-2\n",
    "2019-09-12 23:18:23 rsdg-s3-bucket-fin-demo\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## List the files in the **rsdg-s3-bucket-fin-demo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls s3://rsdg-s3-bucket-fin-demo/ --profile fin-demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## Use boto3 package to query the s3 bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "_session = boto3.Session(profile_name='fin-demo')\n",
    "s3 = _session.client('s3')\n",
    "s3.list_objects_v2(Bucket='rsdg-s3-bucket-fin-demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## Process boto3 json to build a dictionary of files and objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s3_keys(bucket):\n",
    "    \"\"\"Get a list of keys in an S3 bucket.\"\"\"\n",
    "    _keys = {}\n",
    "    resp = s3.list_objects_v2(Bucket=bucket)\n",
    "    for obj in resp['Contents']:\n",
    "        _key = obj['Key']\n",
    "        _size = obj['Size']\n",
    "        _keys[_key] = _size\n",
    "    return _keys\n",
    "\n",
    "keysAndSizes = {}\n",
    "keysAndSizes = get_s3_keys('rsdg-s3-bucket-fin-demo')\n",
    "print(keysAndSizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## Load the dictionary into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pdKeysAndSizes = pd.DataFrame(list(keysAndSizes.items()))\n",
    "pdKeysAndSizes.columns = ['FileName', 'Size']\n",
    "pdKeysAndSizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "## Use pandas to count the number of files and total size of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of files: %s; Total size of files (MB): %s\" % (pdKeysAndSizes.count()['FileName'],\n",
    "                                                        pdKeysAndSizes.sum(axis=0)['Size']/1024/1024\n",
    "                                                       ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample the file to understand the structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smart_open as so\n",
    "ii = 0\n",
    "for line in so.open('s3://rsdg-s3-bucket-fin-demo/aapl.us.txt', transport_params=dict(session= _session) ):\n",
    "    ii += 1\n",
    "    if(ii < 10):\n",
    "        print(line)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load \"aapl\" file into data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "equity_df = pd.read_csv(so.open('s3://rsdg-s3-bucket-fin-demo/aapl.us.txt', transport_params=dict(session= _session) ))\n",
    "equity_df['Stock']='aapl.us.txt'.replace('.txt','')\n",
    "equity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the files into data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_equity_df = pd.DataFrame()\n",
    "\n",
    "for key in keysAndSizes:\n",
    "    file = 's3://rsdg-s3-bucket-fin-demo/' + key\n",
    "    single_equity_df = pd.DataFrame()\n",
    "    single_equity_df = pd.read_csv(so.open(file, transport_params=dict(session= _session) ))\n",
    "    single_equity_df['Stock'] = key.replace('.txt','')\n",
    "    combined_equity_df = combined_equity_df.append(single_equity_df, ignore_index=True)\n",
    "        \n",
    "print(combined_equity_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Back to readme\n",
    "* [00-Setup](/markdown/setup.md) \n",
    "* [01-Process S3 using python](https://nbviewer.jupyter.org/github/satishrsdg/aws-finance-analytics-demo/blob/master/jupyter-lab/process_s3_files.ipynb?flush_cache=true)\n",
    "* [02-Visualization and Analytics](./02_Visualization_and_Analytics.ipynb)\n",
    "* [03-Risk Analytics](./03_Risk_Analytics.ipynb)\n",
    "* [04-Exploring Firehose,Athena and Quicksight](./04_Exploring_Kinesis_Firehose.ipynb)\n",
    "* [05-Athena and Quicksights](./05_Athena_Quicksight.ipynb)\n",
    "* [06-Sagemaker to run the notebooks](./06_Sagemaker_jupyterlab.ipynb)\n",
    "* [07_Transform stream data using Lambda](./07_Transform_lambda.ipynb)\n",
    "* [08_Move data to Redshift using Glue](./08_Glue_Redshift.ipynb)\n",
    "* [09_CI/CD Terrform with Travis CI](./09_Integrating_terraform_travisci.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
